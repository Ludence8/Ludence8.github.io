---
layout: post
title: "[DL, Pytorch] SW중심대학 AI 경진대회 끄적이기_3"
tags: [DL, pandas, pytorch]
math: true
date: 2025-07-23 22:00 +0900
categories:
    - Study
toc: true
---
데이콘 주소 : https://dacon.io/competitions/official/236473/overview/description
* * *
## 데이터 확인
1.train.csv   
![제목](\assets\traincsv.png){: width="40%" height="40%"}  
데이터 개수 : 약 10만개    
데이터 구성 : 제목, 글, 생성 여부    
특이사항 : 데이터 글이 길다. 매우 길다. 또한 영어가 아닌 한국어로 작성되어 있다. 이에 따른 처리 방식에 대해 고민해봐야할 것 같다.   
2.test.csv   
train.csv와 동일한 형태지만 생성 여부만 없는 전형적인 평가용 파일. 해당 파일을 분류하는게 목표.   
* * *
## 해결 방법 고민 
dacon 게시판에 순수 제출만을 위한 방식으로 XGBoost를 사용한 코드가 존재했다.   
먼저 이 방법을 통해 학습을 진행했다.   
또한 데이터가 영어가 아니라 한국어인 만큼 토큰화에 대한 고민을 많이 했다.   
   
https://konlpy.org/ko/latest/   
KoNLPy라는 패키지에서 okt, Komoran, Mecab 등의 여러 한국어 특화 토크나이저들을 받아 사용할 수 있음을 찾았고 이걸 사용해보자고 마음을 먹었다.   
![제목](\assets\okt.png){: width="40%" height="40%"}   
okt를 받아서 사용해보니 꽤나 나쁘지 않게 쪼개줌을 볼 수 있었다.   
여기에 XGBoost 예제 코드에 레이블 편향에 따른 가중치 수정 코드를 주고, 수치들을 조금씩 조정해가면서 최종 코드를 완성시켰다.   

## 코드 구성
1.데이터 불러오기
2.토큰화(Okt Tockenizer)   
3.모델 제작(Using XGBoost).  
4.학습   

## 학습 결과
![제목](\assets\result.png){: width="40%" height="40%"}   
아쉽게도 submission을 제출했을 때 결과가 0.67이라는 꽤나 나쁜 결과를 얻었다.   
대회 1등이 0.94인 것을 보아 상당히 못한 결과였다고 생각한다.   

## FeedBack
처음으로 참여해본 Dacon 대회였고, AI 공부는 cnn이 무엇인지, gan이 무엇인지 책으로 더듬더듬 쳐가며 공부했던 것이 처음이였는데, 나름 재미는 있었던 것 같다.   
무작정 들이받아본 만큼 꽤나 빠르게 많은 것들을 느꼈던 것 같지만, 그만큼 속성으로 공부한 것 같아 추가적인 공부가 병행되어야 할 것 같다.   
   
먼저 대회가 끝난 후 데이터들을 다시 살펴보았을 때, 모든 데이터가 글 형태로 되어있지만은 않았다.   
결측치가 존재하진 않았지만 단순한 문자열들의 나열,엄청나게 긴 하나의 문장 등등 학습에 오히려 악영향을 줄 수 있는 요소들이 꽤나 많음을 확인할 수 있었고, 이들을 좀 빼고 학습을 했어도 성능이 조금은 오르지 않았을까..싶었다.   
학습은 머신러닝 방법론인 XGBoost를 사용함으로써 크게 기대하지 않았으나, 처음 잡았던 방향성인 BigBird, BERT, loberta와 같은 모델을 써서 fine-tuning을 했다면 훨 좋은 성능을 내지 않았을까 생각이 든다.   
이 과정에서 colab에만 기대는 것이 아니라 kaggle과 같은 다른 서버 대여를 알아보거나, 금액을 지불하여 서버를 대여한 뒤 실제 학습을 돌려봤다면 0.7은 넘지 않았을까....하는 아쉬움이 남았다.   
   
=> 앞으로 데이터 전처리에 대해 공부해볼까도 고민된다
