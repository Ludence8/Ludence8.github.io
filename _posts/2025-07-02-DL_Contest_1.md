---
layout: post
title: "[DL, Pytorch] SW중심대학 AI 경진대회 끄적이기"
tags: [DL, pandas, pytorch]
math: true
date: 2025-07-07 22:00 +0900
categories:
    - Study
toc: true
---
데이콘 주소 : https://dacon.io/competitions/official/236473/overview/description
* * *
## 데이터 확인
1.train.csv   
![제목](\assets\traincsv.png){: width="40%" height="40%"}  
데이터 개수 : 약 10만개    
데이터 구성 : 제목, 글, 생성 여부    
특이사항 : 데이터 글이 길다. 매우 길다. 또한 영어가 아닌 한국어로 작성되어 있다. 이에 따른 처리 방식에 대해 고민해봐야할 것 같다.   
2.test.csv   
train.csv와 동일한 형태지만 생성 여부만 없는 전형적인 평가용 파일. 해당 파일을 분류하는게 목표.   
* * *
## 해결 방법 고민 
우선 필자는 이번 대회가 첫 AI 관련 대회로써 참여의 목적을 두고 이것저것 알아보았다.   
초기 고민사항    
https://huggingface.co/docs/transformers/ko/model_doc/deberta   
huggingface에 올라와있는 DeBERTa 모델을 Fine-Tuning해서 사용하기로 처음 생각하였음.    
간단하게 맛만 보기 위해 로컬 환경에서 작업을 진행하였다.   
![제목](\assets\deBERTaStudy.png){: width="40%" height="40%"}    
학습 시간 : 약 13시간   
epoch : 3   
   
근데 여기서 문제가 발생. 테스트 데이터를 전부 0으로 예측한 것이였다.   

### 원인 분석
1.학습 데이터 편향.  
![제목](\assets\classWeight.png){: width="40%" height="40%"}  
학습 데이터를 분석해본 결과 0과 1의 편향이 매우 크게 나타났다. 이에 따라 컴퓨터가 일단 0으로 예측하는 방향으로 학습이 이뤄지지 않았을까 추측이 들었다.   
이에 따라 0으로 예측해서 틀렸을 때 손해를 크게 주는 방식으로 weight를 조절하는 것도 나쁘지 않겠다 생각이 들었다.   
2.DeBERTa 자체 문제   
DeBERTa는 입력 시퀀스의 최대 토큰 수가 512로, 이번 데이터처럼 매우 긴 데이터를 처리하는 데에는 적합하지 않다.   
이에 따라 Sliding Window를 통한 처리를 하거나 LongFormer, BigBird 등의 다른 모델을 사용하는 방법을 고민해야할 것 같다.    
출처 : https://ncsoft.github.io/ncresearch/6fc502ede05ca318787928fa22332a82b112805b

